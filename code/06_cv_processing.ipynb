{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equipped-fight",
   "metadata": {},
   "source": [
    "#### Data Processing: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-rates",
   "metadata": {},
   "source": [
    "This notebook contains the functions and code used to process the audio files obtained from commonvoice.mozilla.org\n",
    "\n",
    "These samples were obtained later in the process than the first four sources, and were originally intended for use exclusively as validation samples. These samples were, in general, shorter than the previous samples, so they didn't need to be split into many pieces, but also went through a different process because near the end of the project I began to prioritize computer storage space over runtime. This is why they were transformed from audio to timeseries to mfcc without saving in between. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "after-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "parallel-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from librosa.feature import mfcc\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "unlikely-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_file_listing(source, lang_abbr):\n",
    "    \"\"\"\n",
    "    Lists the path names for all the audio files for a given source and language.\n",
    "    \n",
    "    Parameters:\n",
    "        source (str) : the folder name where a source's audio is saved\n",
    "        lang_abbr (str) : the two letter abbreviation of the language to list audio samples of\n",
    "    \n",
    "    Returns:\n",
    "        file_listing (numpy array) : the path names for all the source's audio files of the specified language\n",
    "    \"\"\"\n",
    "    base_path = '../audio/' + source + '/' + lang_abbr + '/'\n",
    "    return np.array(\n",
    "        [base_path + f for i, f in list(enumerate(listdir(base_path))) if (\n",
    "            ('.mp3' in f) or ('.wav' in f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unauthorized-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc_target(folder, source, abbr, n_mfcc=10):\n",
    "    \"\"\"\n",
    "    Saves the master mfcc array and corresponding target array\n",
    "    \n",
    "    Parameters:\n",
    "        folder (str) : the file path to save to\n",
    "        source (str) : the folder name where a source's audio is saved\n",
    "        abbr (str) : the two letter abbreviation of the language to save\n",
    "        n_mfcc (int) : the number of Mel frequency cepstrum coefficients to be calculated (default 10)\n",
    "    \"\"\"\n",
    "    audio_in_path = '../audio/' + source + '/' + abbr + '/'\n",
    "    mfcc_out_path = '../data/' + folder + '/' + source + '_' + abbr + '_mfcc.pkl'\n",
    "    target_out_path = '../data/' + folder + '/' + source + '_' + abbr + '_target.pkl'\n",
    "    \n",
    "    mfcc_arr, target_arr = mfcc_and_target(audio_in_path, n_mfcc)\n",
    "    \n",
    "    with open(mfcc_out_path, 'wb') as f:\n",
    "        pickle.dump(mfcc_arr, f)\n",
    "    with open(target_out_path, 'wb') as g:\n",
    "        pickle.dump(target_arr, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "genuine-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mfcc(mfcc_arr, file, sample_n, n_mfcc=10):\n",
    "    \"\"\"\n",
    "    Adds a sample's mfcc to the master array\n",
    "    \n",
    "    Parameters:\n",
    "        mfcc_arr (numpy array) : the master array to add to\n",
    "        file (str) : the file path of the audio sample to add\n",
    "        sample_n (int) : the sample number of the file, used to index the mfcc to be added\n",
    "        n_mfcc (int) : the number of Mel frequency cepstrum coefficients to be calculated (default 10)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timeseries, sr = librosa.load(file, sr=16000)\n",
    "        trimmed, x = librosa.effects.trim(timeseries)\n",
    "\n",
    "        if len(trimmed) / 16000 > 5:\n",
    "            sample = trimmed[:5 * 16000]\n",
    "        else:\n",
    "            pad = ((5 * 16000) - len(trimmed)) / 2\n",
    "            sample = np.pad(trimmed, [int(np.floor(pad)), int(np.ceil(pad))])\n",
    "\n",
    "        mfcc_arr[sample_n] = mfcc(sample, sr=16000, n_mfcc=n_mfcc)\n",
    "    except:\n",
    "        mfcc_arr[sample_n] = np.full((n_mfcc, 157), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "published-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_and_target(path_in, n_mfcc=10):\n",
    "    \"\"\"\n",
    "    Creates arrays of mfccs and language target values\n",
    "    \n",
    "    Parameters\n",
    "        path_in (str) : file path to folder of audio files ('../audio/[source]/[abbr]/')\n",
    "        n_mfcc (int) : number of mel frequency cepstrum coefficients to be calculated\n",
    "    \n",
    "    Returns\n",
    "        mfcc_arr (numpy array) : array of mfcc matrices for each file\n",
    "        target_arr (numpy array) : array of language abbreviation target values corresponding to mfcc_arr\n",
    "    \"\"\"\n",
    "    path_in_split = path_in.split('/')\n",
    "    \n",
    "    source = path_in_split[-3]\n",
    "    abbr = path_in_split[-2]\n",
    "    \n",
    "    audio_files = audio_file_listing(source, abbr)\n",
    "    size = len(audio_files)\n",
    "    \n",
    "    mfcc_arr = np.full((size, n_mfcc, 157), np.nan)\n",
    "    \n",
    "    num_arr = np.array(range(size))\n",
    "    \n",
    "    func = np.vectorize(lambda x: add_mfcc(mfcc_arr, audio_files[x], x, n_mfcc))\n",
    "    func(num_arr)\n",
    "    \n",
    "    target_arr = np.full(size, abbr)\n",
    "    mfcc_arr = mfcc_arr.reshape(size, n_mfcc, 157)\n",
    "    \n",
    "    return mfcc_arr, target_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "heavy-shareware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 40s, sys: 1min 18s, total: 39min 58s\n",
      "Wall time: 26min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_mfcc_target('validation', 'v_commonvoice', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "korean-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39min 3s, sys: 1min 38s, total: 40min 42s\n",
      "Wall time: 30min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_mfcc_target('validation', 'v_commonvoice', 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "distant-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 22s, sys: 1min 31s, total: 37min 54s\n",
      "Wall time: 24min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_mfcc_target('validation', 'v_commonvoice', 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "funny-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 55s, sys: 1min 42s, total: 45min 37s\n",
      "Wall time: 33min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_mfcc_target('validation', 'v_commonvoice', 'ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unusual-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 23s, sys: 1min 51s, total: 54min 14s\n",
      "Wall time: 43min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_mfcc_target('validation', 'v_commonvoice', 'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-rental",
   "metadata": {},
   "source": [
    "After a long wait time, all the mfcc and target arrays had been saved, but because I had exceptions return arrays of NaNs, I had to reload the files to remove those from the listing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "native-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "valpath = '../data/validation/'\n",
    "\n",
    "mfcc_val = [valpath + f for f in listdir(valpath) if 'mfcc.pkl' in f]\n",
    "target_val = [valpath + f for f in listdir(valpath) if 'target.pkl' in f]\n",
    "\n",
    "mfcc_val.sort()\n",
    "target_val.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload(path):\n",
    "    \"\"\"\n",
    "    Reloads a pickled file\n",
    "    \n",
    "    Parameters:\n",
    "        path (str) : the file path of the pickle\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endangered-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mfcc_reloaded = [reload(f) for f in mfcc_val]\n",
    "val_target_reloaded = [reload(f) for f in target_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "purple-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the reloaded arrays, remove any entries of NaNs and save a new target array of the correct length\n",
    "for i, j in zip(val_mfcc_reloaded, val_target_reloaded):\n",
    "    abbr = j[0]\n",
    "    X = i[~np.isnan(i)]\n",
    "    size = X.shape[0] // 157 // 10\n",
    "    y = np.full(size, abbr)\n",
    "    with open('../data/validation/commonvoice_' + abbr + '_mfcc.pkl', 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "    with open('../data/validation/commonvoice_' + abbr + '_target.pkl', 'wb') as g:\n",
    "        pickle.dump(y, g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
