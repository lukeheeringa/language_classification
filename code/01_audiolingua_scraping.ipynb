{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "promising-intersection",
   "metadata": {},
   "source": [
    "#### Data Collection: Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-mixture",
   "metadata": {},
   "source": [
    "This notebook contains the functions that were used to mass download audio files from audio-lingua.eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strange-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amazing-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(res, language, filename):\n",
    "    \"\"\"\n",
    "    Saves mp3 audio files\n",
    "    \n",
    "    Args:\n",
    "        res: request object of the audio file page\n",
    "        language: language spoken in sample\n",
    "        filename: file name to be saved as\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open('../audio/1_audiolingua/' + language + '/' + filename + '.mp3', 'wb') as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technical-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagelist(url, language):\n",
    "    \"\"\"\n",
    "    Pulls, saves, and documents all the samples linked on a given audio-lingua webpage\n",
    "    \n",
    "    Args:\n",
    "        url: string of the webpage address\n",
    "        language: language of the samples on the page\n",
    "    \n",
    "    Returns:\n",
    "        samples: a pandas dataframe of the new samples saved and added to the master list\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.audio-lingua.eu/'\n",
    "    page_dict = {}\n",
    "    \n",
    "    page_res = requests.get(url)\n",
    "    soup = BS(page_res.text)\n",
    "    \n",
    "    # find the first 5 article entries on the page--beyond that have no download links\n",
    "    entries = soup.find_all(name='article', attrs={'class' : 'entry article hentry'})[:5]\n",
    "    \n",
    "    # iterate through page posts\n",
    "    for entry in entries:\n",
    "        try:\n",
    "            # request object is the download link\n",
    "            entry_res = entry.find(name='a', attrs={'title' : 'Download'})\n",
    "            # go to direct download page\n",
    "            audio_res = requests.get(base_url + entry_res['href'])\n",
    "            # grab the name prior to the extension\n",
    "            fname = entry_res['href'].split('/')[2].split('.')[0]\n",
    "            # grab the labels on the entry\n",
    "            labels = [label.text.strip() for label in entry.find_all(\n",
    "                name='a', attrs={'class' : 'label'}\n",
    "            )]\n",
    "\n",
    "            # save audio files\n",
    "            writefile(audio_res, language, fname)\n",
    "\n",
    "            # add audio entries to dictionary\n",
    "            page_dict.update({\n",
    "                fname : {'language' : language, 'labels' : labels}\n",
    "            })\n",
    "        # if there is an error (usually because entries is an empty list), end the attempt\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # samples to be updated\n",
    "    samples = pd.DataFrame(page_dict).T\n",
    "    samples.reset_index(inplace=True)\n",
    "    samples.rename(columns={'index' : 'file_name'}, inplace=True)\n",
    "    \n",
    "    # add to file listing\n",
    "    update_listing(samples)\n",
    "    \n",
    "    # show added samples\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distinguished-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_listing(df):\n",
    "    \"\"\"\n",
    "    Updates and saves the master list of samples.\n",
    "    \n",
    "    Args:\n",
    "        df: a pandas dataframe of the new samples to be added \n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_listing = pd.read_csv('../audio/1_audiolingua/file_listing.csv')\n",
    "    except:\n",
    "        file_listing = pd.DataFrame(columns=['file_name', 'language', 'labels'])\n",
    "        \n",
    "    file_listing = pd.concat([file_listing, df])\n",
    "    file_listing = file_listing.drop_duplicates(subset='file_name', keep='last')\n",
    "    file_listing.to_csv('../audio/1_audiolingua/file_listing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beautiful-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples():\n",
    "    \"\"\"\n",
    "    Shows the number of samples collected for each language. \n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series of languages and their counts\n",
    "    \"\"\"\n",
    "    return pd.read_csv('../audio/1_audiolingua/file_listing.csv')['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-appreciation",
   "metadata": {},
   "source": [
    "The only languages with samples collected from audio-lingua were English and Mandarin, as during the course of the project the website's certificate changed or expired, leaving it no longer entirely safe to be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "macro-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_base = 'https://www.audio-lingua.eu/spip.php?rubrique2&lang=en'\n",
    "pages = list(range(0, 501, 5))\n",
    "\n",
    "for p in pages:\n",
    "    pagelist(en_base + '&debut_articles=' + str(p) + '#pagination_articles', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "communist-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_base = 'https://audio-lingua.eu/spip.php?rubrique9&lang=en'\n",
    "pages = list(range(0, 501, 5))\n",
    "\n",
    "for p in pages:\n",
    "    pagelist(zh_base + '&debut_articles=' + str(p) + '#pagination_articles', 'zh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
